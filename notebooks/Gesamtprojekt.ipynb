{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:DarkBlue;font-size:32px\">Preisvorhersage von Gebrauchtwagen </span>\n",
    "\n",
    "<span style=\"color:DarkBlue;font-size:18px\">Semesterabschließende schriftliche Ausarbeitung im Modul Machine Learning (SS2023)</span>\n",
    "\n",
    "<span style=\"color:DarkBlue;font-size:18px\"> Bearbeitet von M.Sc. Onur Yilmaz</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inhaltsverzeichnis**\n",
    "\n",
    "[Einleitung](#Einleitung)\n",
    "\n",
    "[1. Datenaufbereitung](#Datenaufbereitung)\n",
    "\n",
    "[1.1. Daten extrahieren](#Daten-extrahieren)\n",
    "\n",
    "[1.2. Daten bereinigen](#Daten-bereinigen)\n",
    "\n",
    "[1.3. Daten transformieren](#Daten-transformieren)\n",
    "\n",
    "[2. Explorative Datenanalyse](#Explorative-Datenanalyse)\n",
    "\n",
    "[2.1. Univariate Analyse](#Univariate-Analyse)\n",
    "\n",
    "[2.2. Bivariate Analyse](#Bivariate-Analyse)\n",
    "\n",
    "[2.3. Multivariate Analyse](#Multivariate-Analyse)\n",
    "\n",
    "[3. Feature Engineering](#Feature-Engineering)\n",
    "\n",
    "[4. Modell Auswahl und Training ](#Modell-Auswahl-und-Training)\n",
    "\n",
    "[4.1. Modell Auswahl](#Modell-Auswahl)\n",
    "\n",
    "[4.2. Ensemble Modell - XGBoost ](#XGBoost)\n",
    "\n",
    "[5. Modell Bewertung](#Modell-Bewertung)\n",
    "\n",
    "[6. Streamlit](#Streamlit)\n",
    "\n",
    "[Literaturverzeichnis](#Literaturverzeichnis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Einleitung\"></a>**Einleitung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der vorliegenden semesterabschließenden Arbeit wird ein aufbereiteter Datensatz von 100.000 gebrauchten Autoanzeigen aus dem Vereinigten Königreich analysiert. Der Datensatz wurde von der Plattform Kaggle bezogen - **https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes**.\n",
    "\n",
    "Das Hauptziel dieser Arbeit ist die Wahl und Implementierung eines geeigneten maschinellen Lernmodells zur Preisvorhersage von Gebrauchtwagen.\n",
    "\n",
    "Die Arbeit gliedert sich in verschiedene Abschnitte, beginnend mit der Datenaufbereitung, gefolgt von der explorativen Datenanalyse und dem Feature Engineering. Anschließend wird das passende Modell ausgewählt und trainiert, bevor es bewertet wird. Zusätzlich wird die Implementierung in Streamlit durchgeführt, um eine interaktive Webanwendung zur Darstellung der Ergebnisse zu erstellen.\n",
    "\n",
    "Der Datensatz ist in einzelne Dateien nach Autoherstellern unterteilt und enthält Informationen wie Preis, Getriebe, Kilometerstand, Kraftstoffart, Kfz-Steuer, Verbrauch in Meilen pro Gallone (mpg) und Motorgröße.\n",
    "\n",
    "**Das gesamte Projekt kann aus dem folgenden Repository geklont werden: https://www.github.com/ONURYI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Datenaufbereitung\"></a>**1. Datenaufbereitung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-extrahieren\"></a>**1.1. Daten extrahieren**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datenaufbereitung stellt im Prozess des maschinellen Lernens oft einen entscheidenden, aber zugleich zeitaufwendigen Schritt dar. Sie umfasst diverse Techniken zur Säuberung, Transformation und Organisation der Rohdaten, um sie in ein für die Analyse passendes Format zu überführen. Diese Etappe legt das solide Fundament für die Erstellung eines Modells, da sie die Qualität und Relevanz der Daten gewährleistet. Dies trägt maßgeblich zur Präzision und Leistungsfähigkeit des endgültigen Modells bei [2].\n",
    "\n",
    "Im Kontext unseres Projektes verwenden wir folgende CSV-Dateien (CSV = Comma-Separated Values):\n",
    "\n",
    "- audi.csv\n",
    "- bmw.csv\n",
    "- ford.csv\n",
    "- hyundai.csv\n",
    "- mercedes.csv\n",
    "- skoda.csv\n",
    "- toyota.csv\n",
    "- vauxhall.csv (unbenannt in opel)\n",
    "- vw.csv\n",
    "\n",
    "Diese Dateien sind im Ordner **/data** gespeichert und werden nach dem Aufbereitungs- und Bereinigungsprozess im Ordner **/data (clean)** als einzige zusammengefasste CSV-Datei abgelegt.\n",
    "\n",
    "Für diesen Abschnitt wird ausschließlich auf die weit verbreitete **Pandas-Bibliothek** zurückgegriffen, welche sich als leistungsfähiges Werkzeug zur Datenmanipulation und -analyse etabliert hat. Hierbei lesen wir die Daten aus und stellen die Daten als sog. **DataFrames** dar, da sie eine standardisierte, zweidimensionale Struktur bieten, die das Speichern, Manipulieren und Analysieren von tabellarischen Daten vereinfacht, wodurch die Datenanalyse und -verarbeitung insgesamt effizienter und übersichtlicher wird [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir lesen nun die ersten CSV-Files aus, uns erst einmal einen Überblick zu verschaffen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audi =  pd.read_csv('../data/audi.csv')\n",
    "df_ford  =  pd.read_csv('../data/ford.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ford.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Befehl *df.shape* gibt uns Auskunft über die zugehörige Dimension unseres DataFrames. Die erste Zahl, gibt die Anzahl der Zeilen und die zweite Zahl, die Anzahl der Spalten (auch Variable oder Merkmale genannt) wieder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_audi.shape)\n",
    "print(df_ford.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um schließlich einen umfassenden Datensatz zu erhalten, fassen wir diesen in einem DataFrame zusammen, wobei wir eine zusätzliche Spalte hinzugefügt haben, die als brand bezeichnet wird und die Marke des Modells enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    '../data/audi.csv',\n",
    "    '../data/bmw.csv',\n",
    "    '../data/ford.csv',\n",
    "    '../data/hyundai.csv',\n",
    "    '../data/mercedes.csv',\n",
    "    '../data/skoda.csv',\n",
    "    '../data/toyota.csv',\n",
    "    '../data/opel.csv',\n",
    "    '../data/vw.csv',\n",
    "]\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "# Durchlaufe alle Dateipfade und lade die CSV-Dateien\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    brand = file_path.split('/')[-1].split('.')[0]  # Extrahiere die Marke aus dem Dateinamen\n",
    "    df['brand'] = brand  # Füge eine Spalte mit der Marke hinzu\n",
    "    # Ändere die Reihenfolge der Spalten, um \"brand\" an den Anfang zu setzen\n",
    "    df = df[['brand'] + [col for col in df.columns if col != 'brand']]\n",
    "    all_dataframes.append(df)\n",
    "\n",
    "df = pd.concat(all_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-bereinigen\"></a>**1.2. Daten bereinigen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um redundate Daten vorzubeugen müssen wir vorab unsere Daten auf Duplikate prüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_count = df.duplicated().sum()\n",
    "print(duplicate_count)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insgesamt hat sich der Datensatz somit um 1457 Zeilen reduziert. \n",
    "\n",
    "Als nächsten Schritt prüfen wir den Datensatz anschließend auf fehlende Werte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt fehlende Werte in den Spalten tax, mpg, und tax(£). \n",
    "\n",
    "Gerade die Spalte tax(£) scheint in einem großen Teil des Datensatzes zu fehlen, weshalb wir die Spalte entfernen können, aufgrund fehlendem Informationsgehalt.\n",
    "\n",
    "\n",
    "Die anderen Spalten könnten wir die fehlenden Werte mit geeigneten Methoden behandeln, wie z.B. durch das Ausfüllen mit dem Durchschnittswert oder Median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['tax(£)'])\n",
    "df['tax'].fillna(df['tax'].median(), inplace=True)\n",
    "df['mpg'].fillna(df['mpg'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun nachdem wir geprüft haben, dass auch die Daten keine fehlenden Werte (**missing values**) mehr enthalten, müssen wir nun schauen das unsere Daten insgesamt plausibel sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['year'].min())\n",
    "print(df['year'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese problematischen Zeilen müssen wir nun einmal filtern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['year'] != 1970) & (df['year'] != 2060)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_counts = df['transmission'].value_counts()\n",
    "\n",
    "print(\"Einzelne eindeutige Werte und ihre Häufigkeit:\")\n",
    "print(unique_values_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_counts = df['fuelType'].value_counts()\n",
    "\n",
    "print(\"Einzelne eindeutige Werte und ihre Häufigkeit:\")\n",
    "print(unique_values_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-transformieren\"></a>**1.3. Daten transformieren**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es sich bei dem vorliegenden Datensatz um einen UK-Datensatz handelt, waren die Spalten und Zeilen ursprünglich für den englischsprachigen Raum konzipiert. Um jedoch eine bessere Interpretierbarkeit unserer Daten im deutschsprachigen Kontext zu gewährleisten, haben wir die Daten entsprechend transformiert. \n",
    "\n",
    "**Es ist wichtig zu betonen, dass die Konvertierung von Einheiten und die Abweichung von den Rohdaten problematisch sein können!**\n",
    "\n",
    "Hierbei wurde [4] hinzugezogen um noch einmal auf die Richtigkeit der Funktionen zu überprüfen und nachzujustieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion Umrechnung von (mpg) zu (l/100km)\n",
    "def mpg_to_l_per_100km(mpg):\n",
    "    return 235.215 / mpg\n",
    "\n",
    "# Funktion Umrechnung Meilen zu km\n",
    "def miles_to_km(miles):\n",
    "    return miles * 1.60934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    'Marke', 'Modell', 'Baujahr', 'Preis (£)', 'Getriebe', 'Kilometerstand', 'Kraftstoffart', 'Steuer (£)', 'Verbrauch (l/100km)', 'Motorgröße (l)']\n",
    "\n",
    "df['Getriebe'] = df['Getriebe'].map({'Manual': 'Manuell', \n",
    "                                     'Automatic': 'Automatik', \n",
    "                                     'Semi-Auto': 'Halbautomatisch',\n",
    "                                     'Other': 'Andere'})\n",
    "\n",
    "df['Kraftstoffart'] = df['Kraftstoffart'].map({'Petrol': 'Benzin', \n",
    "                                               'Diesel': 'Diesel', \n",
    "                                               'Hybrid': 'Hybrid',\n",
    "                                               'Other': 'Andere',\n",
    "                                               'Electric': 'Elektrisch'})\n",
    "\n",
    "df['Kilometerstand'] = df['Kilometerstand'].apply(miles_to_km).astype(int)\n",
    "\n",
    "df['Verbrauch (l/100km)'] = df['Verbrauch (l/100km)'].apply(mpg_to_l_per_100km).round(2)\n",
    "\n",
    "df['Marke'] = df['Marke'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wechselkurs von Pfund zu Euro festlegen\n",
    "exchange_rate = 1.15\n",
    "\n",
    "# Umrechnung der Preise und Steuern von Pfund in Euro\n",
    "df['Preis (€)'] = df['Preis (£)'] * exchange_rate\n",
    "df['Steuer (€)'] = df['Steuer (£)'] * exchange_rate\n",
    "\n",
    "df['Preis (€)']\n",
    "\n",
    "\n",
    "# Entfernen der alten Spalten in Pfund\n",
    "df.drop(columns=['Preis (£)', 'Steuer (£)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = ['Marke', 'Modell', 'Getriebe', 'Kraftstoffart']\n",
    "\n",
    "# Leerzeichen in den ausgewählten Spalten entfernen\n",
    "df[string_columns] = df[string_columns].apply(lambda x: x.str.replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen der unerwünschten Ausprägungen in 'Getriebe' und 'Kraftstoffart'\n",
    "df = df[(df['Getriebe'] != 'Andere') & \n",
    "                 (df['Kraftstoffart'] != 'Elektrisch') & \n",
    "                 (df['Kraftstoffart'] != 'Andere')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern unseres bereinigten Datensatzes in der Ordner **\\data (clean)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data (clean)/df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Explorative-Datenanalyse\"></a>**2. Explorative Datenanalyse**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Abschnitt stützt sich auf Konzepte und Methoden aus [5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-bereinigen\"></a>**2.1. Univariate Analyse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der univariaten Analyse werden wir die Verteilung jedes Merkmals einzeln betrachten um uns einen Überblick über die Daten zu verschaffen. \n",
    "\n",
    "Hierfür werden wir sowohl numerische als auch kategoriale Merkmale analysieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "numerical_columns = ['Baujahr', 'Kilometerstand', 'Verbrauch (l/100km)', 'Motorgröße (l)', 'Preis (€)', 'Steuer (€)']\n",
    "\n",
    "# Erstellen von Subplots für jede numerische Variable\n",
    "for i, col in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[col], bins=20, kde=True)\n",
    "    plt.title(f'Verteilung von {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Anzahl')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Histogramme zeigen die Verteilung der einzelnen numerischen Merkmale:\n",
    "\n",
    "- Baujahr: Die meisten Autos wurden zwischen 2016 und 2020 gebaut.\n",
    "\n",
    "- Kilometerstand: Die Verteilung ist rechtsschief, wobei die meisten Autos einen niedrigen Kilometerstand haben.\n",
    "\n",
    "- Verbrauch (l/100km): Die meisten Autos haben einen Verbrauch zwischen 3 und 6 Litern pro 100 Kilometer. \n",
    "\n",
    "- Motorgröße (l): Die meisten Autos haben eine Motorgröße zwischen 1 und 2 Litern.\n",
    "\n",
    "- Preis (€): Die Verteilung des Preises ist rechtsschief, wobei die meisten Autos im niedrigeren Preissegment liegen.\n",
    "\n",
    "- Steuer (€): Die Steuern variieren, wobei die meisten Autos Steuern im Bereich von 100 bis 200 € haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun betrachten wir noch die Verteilungen der kategorischen Merkmale: \"Marke\", \"Getriebe\" und \"Kraftstoffart\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "categorical_columns = ['Marke', 'Getriebe', 'Kraftstoffart']\n",
    "\n",
    "# Erstellen von Subplots für jede kategorische Variable\n",
    "for i, col in enumerate(categorical_columns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.countplot(data=df, y=col, order=df[col].value_counts().index)\n",
    "    plt.title(f'Verteilung von {col}')\n",
    "    plt.xlabel('Anzahl')\n",
    "    plt.ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Variable Modell zu viele Ausprägungen besitzt beschränken wir uns auf die Top-3-Modelle für jede der Top-5-Marken in den Daten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_brands = df['Marke'].value_counts().nlargest(5).index.tolist()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, brand in enumerate(top_5_brands, 1):\n",
    "    top_3_models = df[df['Marke'] == brand]['Modell'].value_counts().nlargest(3)\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.barplot(x=top_3_models.index, y=top_3_models.values, palette='viridis')\n",
    "    plt.title(f'Top-3-Modelle für {brand}')\n",
    "    plt.xlabel('Modell')\n",
    "    plt.ylabel('Anzahl')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-bereinigen\"></a>**2.2. Bivariate Analyse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Korrelationsanalyse ist eine spezifische Form der bivariaten Analyse, bei der wie die lineare Beziehung zwischen zwei Merkmalen mit Hilfe des sog. *Pearson-Korrelationskoeffizient* messen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen von Scatterplots für Preis gegen andere numerische Merkmale\n",
    "numerical_columns.remove('Preis (€)')\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.scatterplot(x=df[feature], y=df['Preis (€)'], alpha=0.5, edgecolor=None)\n",
    "    plt.title(f'Preis vs. {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Preis (€)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preis vs. Baujahr: Es scheint einen positiven Zusammenhang zwischen dem Baujahr und dem Preis zu geben. Neuere Autos tendieren dazu, teurer zu sein.\n",
    "\n",
    "- Preis vs. Kilometerstand: Es gibt einen negativen Zusammenhang zwischen Kilometerstand und Preis. Autos mit höherem Kilometerstand sind tendenziell günstiger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pairings = [('Preis (€)', 'Getriebe'), ('Preis (€)', 'Kraftstoffart')]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (y, x) in enumerate(categorical_pairings, 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    sns.boxplot(x=df[x], y=df[y], palette='viridis')\n",
    "    plt.title(f'{y} nach {x}')\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preis vs. Getriebe: Autos mit Automatikgetriebe scheinen im Durchschnitt teurer zu sein als solche mit manuellem Getriebe.\n",
    "\n",
    "- Preis vs. Kraftstoffart: Die Preise scheinen je nach Kraftstoffart unterschiedlich zu sein. Diesel-Autos sind tendenziell etwas teurer als Benziner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Korrelation**\n",
    "\n",
    "Die Korrelation misst die lineare Beziehung zwischen zwei Variablen. Sie liegt zwischen -1 und +1.\n",
    "\n",
    "Ein positiver Wert zeigt eine positive lineare Beziehung an (d.h., wenn eine Variable steigt, steigt auch die andere),\n",
    "Während ein negativer Wert eine negative lineare Beziehung anzeigt (d.h., wenn eine Variable steigt, sinkt die andere).\n",
    "\n",
    "Eine Korrelation nahe 0 zeigt an, dass zwischen den Variablen keine lineare Beziehung besteht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Korrelationsmatrix')\n",
    "plt.show()\n",
    "\n",
    "# Zeigen der Korrelationen mit dem Preis\n",
    "correlation_with_price = correlation_matrix['Preis (€)'].sort_values(ascending=False)\n",
    "correlation_with_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "numerical_features = ['Baujahr', 'Kilometerstand', 'Verbrauch (l/100km)', 'Motorgröße (l)', 'Preis (€)', 'Steuer (€)']\n",
    "\n",
    "# Berechnen der Korrelationskoeffizienten und p-Werte\n",
    "correlation_p_values = {feature: pearsonr(df['Preis (€)'], df[feature]) for feature in numerical_features if feature != 'Preis (€)'}\n",
    "\n",
    "# Umwandeln in ein DataFrame für eine bessere Darstellung\n",
    "correlation_p_values_df = pd.DataFrame.from_dict(correlation_p_values, orient='index', columns=['Korrelation', 'p-Wert'])\n",
    "correlation_p_values_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle p-Werte sind 0, was bedeutet, dass die Korrelationen statistisch signifikant sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-bereinigen\"></a>**2.4. Multivariate Analyse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "scatter = sns.scatterplot(data=df, x='Kilometerstand', y='Preis (€)', hue='Getriebe', \n",
    "                          palette={'Manuell':'green', 'Automatik':'blue', 'Halbautomatisch':'red'}, alpha=0.7, edgecolor=None)\n",
    "plt.title('Beziehung zwischen Kilometerstand, Preis und Getriebe')\n",
    "plt.xlabel('Kilometerstand')\n",
    "plt.ylabel('Preis (€)')\n",
    "\n",
    "legend_labels = ['Manuell', 'Automatik', 'Halbautomatisch']\n",
    "legend_colors = ['green', 'blue', 'red']\n",
    "markers = [plt.Line2D([0,0],[0,0],color=color, marker='o', linestyle='') for color in legend_colors]\n",
    "plt.legend(markers, legend_labels, title='Getriebe', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeder Punkt auf dem Diagramm repräsentiert ein Auto. Die horizontale Position des Punktes zeigt den Kilometerstand des Autos, während die vertikale Position den Preis des Autos zeigt. Die Farbe des Punktes zeigt das Getriebe des Autos.\n",
    "\n",
    "Autos mit höherem Kilometerstand scheinen tendenziell einen niedrigeren Preis zu haben. Darüber hinaus scheinen Autos mit manuellem Getriebe über das gesamte Spektrum des Kilometerstands und des Preises verteilt zu sein, während Autos mit Automatikgetriebe und halbautomatischem Getriebe  eher in den Bereichen mit niedrigerem Kilometerstand und höherem Preis zu liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Datenaufbereitung\"></a>**3. Feauture Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering ist ein entscheidender Schritt im Prozess des maschinellen Lernens. Es ermöglicht uns, die Daten in einer Weise zu transformieren, die die Effektivität und Effizienz von Modellen verbessert. Durch sorgfältige Modifikation und Auswahl von Merkmalen in unseren Daten können wir Modelle erstellen, die genaue Vorhersagen liefern und leicht zu interpretieren sind. In diesem Abschnitt werden wir das Feature Engineering auf unseren Datensatz anwenden und zeigen, wie es die Genauigkeit unserer Modellvorhersagen verbessern kann.\n",
    "\n",
    "\n",
    "Wir führen noch einmal die obigen Korrelationsergebnisse vor Augen und sehen, dass die Motorgröße, Baujahr und Kilometerstand (negativer Zusammenhang) die größten Einflussfaktoren für unser Modell sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.corr(numeric_only=True)['Preis (€)'].sort_values(ascending=False)\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Da die 'Steuer'-Information in unserem Datensatz nicht intuitiv zu bestimmen ist und daher bei der Anwendung des Preisvorhersagemodells auf neue Daten für den Benutzer schwer einzuschätzen wäre, wurde diese Merkmal für unser Vorhersagemodell enrfernt.**\n",
    "\n",
    "\n",
    "Alle restlichen Spalten wurden hinzugezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Steuer (€)', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns = ['Marke', 'Modell', 'Getriebe', 'Kraftstoffart']\n",
    "encoders = {}\n",
    "for column in label_columns:\n",
    "    encoder = LabelEncoder()\n",
    "    df[column] = encoder.fit_transform(df[column])\n",
    "    encoders[column] = encoder\n",
    "\n",
    "current_year = 2023\n",
    "df['Alter'] = current_year - df['Baujahr']\n",
    "\n",
    "X = df.drop(columns=['Preis (€)'])\n",
    "y = df['Preis (€)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Datenaufbereitung\"></a>**4. Modell Training und Auswahl**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend beziehen sich die Abschnitte auf [6], [7] und [8]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nun kommen wir zum Hauptteil der Arbeit - unserer Preisvorhersage!**\n",
    "\n",
    "Die Preisvorhersage von Gebrauchtwagen unterliegt einem sogenannten **Regressionsproblem** und ist dem **Supervised Learning** (auch *Überwachten Lernen*) zuzuordnen. Die Regression ist ein Modell, das eine kontinuierliche Zielvariable (auch abhängige Variable oder Zielvariable genannt) auf der Grundlage einer oder mehrerer unabhängiger Variablen (auch Merkmale oder Prädiktoren genannt) vorhersagt.\n",
    "\n",
    "Die Funktion  $f$, die wir im Rahmen unseres Regressionsproblems lernen möchten, ist eine Abbildung von einer Feature-Matrix $X$, die aus mehreren Merkmalen besteht, auf einen Zielvektor $y$, der den vorhergesagten Preis darstellt. In einem mathematischen Sinne ist das Ziel der maschinellen Lernmethoden, die zugrunde liegende \"wahre\" Funktion $f$ zu approximieren, die die Beziehung zwischen den Eingangsmerkmalen $X$ und der Ausgabe $y$ beschreibt.\n",
    "\n",
    "\\begin{align*}\n",
    "f: X \\rightarrow y\n",
    "\\end{align*}\n",
    "\n",
    "In der Praxis wissen wir natürlich nicht, was die \"wahre\" Funktion $f$ ist - genau das ist es, was wir herausfinden wollen! Deshalb benutzen wir Algorithmen für maschinelles Lernen, um ein **Modell $\\hat{f}$ zu erzeugen, das unsere beste Schätzung für $f$ ist**. \n",
    "\n",
    "Unser Modell $\\hat{f}$ nimmt die Merkmale eines Autos (wie Marke, Modell, Baujahr, Kilometerstand usw.) als Eingabe und gibt als Ausgabe den geschätzten Preis des Autos aus.\n",
    "\n",
    "\n",
    "Um ein solches Modell zu erstellen, gibt es viele verschiedene Methoden und Algorithmen, die wir verwenden könnten. In dieser Arbeit haben wir uns entschieden, den XGBoost-Algorithmus zu verwenden.\n",
    "\n",
    "**XGBoost, kurz für extreme Gradient Boosting**, ist ein beliebter Algorithmus in der Welt des maschinellen Lernens, insbesondere wenn es um Regressions- und Klassifikationsprobleme geht. Er ist bekannt für seine Leistungsfähigkeit und Effizienz und ist oft eine Top-Wahl in maschinellen Lernwettbewerben und -projekten.\n",
    "\n",
    "XGBoost baut auf der Idee des Gradienten-Boosting auf, wo viele schwache Vorhersagemodelle (in der Regel Entscheidungsbäume) kombiniert werden, um ein starkes Vorhersagemodell zu erstellen. Jedes zusätzliche Modell im Ensemble wird so konfiguriert, dass es die Fehler des bisherigen Modells korrigiert, was zu einem Modell führt, das im Laufe der Zeit immer genauer wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature-Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zielvariable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # (80% Training, 20% Test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Daten-extrahieren\"></a>**5. Modell Bewertung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bestimmheitsmaß:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = xgb_model.score(X_train, y_train)\n",
    "test_score = xgb_model.score(X_test, y_test)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies ist ein ziemlich gutes Ergebnis, da es nahelegt, dass unser Modell nicht überangepasst ist und eine insgesamt eine gute Leistung sowohl auf den Trainingsdaten als auch auf den Testdaten zeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Tatsächlichen Werte')\n",
    "plt.ylabel('Vorhergesagten Werte')\n",
    "plt.title(\"Tatsächliche vs vorhergesagte Werte\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Plot\n",
    "residuals = y_test - y_pred\n",
    "sns.residplot(x=y_pred, y=residuals, lowess=True, line_kws={'color': 'red', 'lw': 1, 'alpha': 1})\n",
    "plt.xlabel('Vorhergesagt')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Literaturverzeichnis**\n",
    "\n",
    "[1] https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes (01.08.2023)\n",
    "\n",
    "[2] Müller, A. C., & Guido, S. (2021). Introduction to Machine Learning with Python: A Guide for Data Scientists (2nd ed.). O'Reilly Media\n",
    "\n",
    "[3] McKinney, W. (2017). Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython (2nd ed.). O'Reilly Media.\n",
    "\n",
    "[4] OpenAI. (2023). Persönliche Kommunikation mit OpenAI's GPT-3.5 Modell. (01.08.2023)\n",
    " \n",
    "[5] Peter Bruce, Andrew Bruce, Peter Gedeck. Praktische Statistik für Data Scientists: 50+ essenzielle Konzepte mit R und Python, 2021.\n",
    "\n",
    "[6] Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani (2013). An Introduction to Statistical Learning: with Applications in R\n",
    "\n",
    "[7] Aurélien Géron (2020). Praxiseinstieg Machine Learning mit Scikit-Learn und TensorFlow: Konzepte, Tools und Techniken für intelligente Systeme. O'Reilly.\n",
    "\n",
    "[8] https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html  (03.08.2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
