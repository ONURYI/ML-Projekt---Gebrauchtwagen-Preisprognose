{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:DarkBlue;font-size:18px\">Semesterabschließende schriftliche Ausarbeitung im Modul Machine Learning (SS2023)</span>\n",
    "\n",
    "<span style=\"color:DarkBlue;font-size:32px\">Preisvorhersage von Gebrauchtwagen </span>\n",
    "\n",
    "<span style=\"color:DarkBlue;font-size:18px\"> Bearbeitet von M.Sc. Onur Yilmaz</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inhaltsverzeichnis\n",
    "\n",
    "#### [Einleitung](#Einleitung)\n",
    "#### [1. Datenaufbereitung](#Datenaufbereitung)\n",
    "##### [1.1. Daten extrahieren](#Daten-extrahieren)\n",
    "##### [1.2. Daten bereinigen](#Daten-bereinigen)\n",
    "##### [1.3. Daten transformieren](#Daten-transformieren)\n",
    "#### [2. Explorative Datenanalyse](#Explorative-Datenanalyse)\n",
    "#### [3. Feature Engineering](#Feature-Engineering)\n",
    "#### [4. Modell Auswahl und Training](#Modell-Auswahl-und-Training)\n",
    "#### [5. Modell Bewertung](#Modell-Bewertung)\n",
    "#### [6. Streamlit](#Streamlit)\n",
    "#### [Literaturverzeichnis](#Literaturverzeichnis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Einleitung\"></a>**Einleitung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der vorliegenden semesterabschließenden Arbeit wird ein aufbereiteter Datensatz von 100.000 gebrauchten Autoanzeigen aus dem Vereinigten Königreich analysiert. Der Datensatz wurde von der Plattform Kaggle bezogen - https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes.\n",
    "\n",
    "Das Hauptziel dieser Arbeit ist die Wahl und Implementierung eines geeigneten maschinellen Lernmodells zur Preisvorhersage von Gebrauchtwagen.\n",
    "\n",
    "Die Arbeit gliedert sich in verschiedene Abschnitte, beginnend mit der Datenaufbereitung, gefolgt von der explorativen Datenanalyse und dem Feature Engineering. Anschließend wird das passende Modell ausgewählt und trainiert, bevor es bewertet wird. Zusätzlich wird die Implementierung in Streamlit durchgeführt, um eine interaktive Webanwendung zur Darstellung der Ergebnisse zu erstellen.\n",
    "\n",
    "Der Datensatz ist in einzelne Dateien nach Autoherstellern unterteilt und enthält Informationen wie Preis, Getriebe, Kilometerstand, Kraftstoffart, Kfz-Steuer, Verbrauch in Meilen pro Gallone (mpg) und Motorgröße.\n",
    "\n",
    "*Das gesamte Projekt kann aus dem folgenden Repository geklont werden: https://www.github.com/ONURYI*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Datenaufbereitung\"></a>**1. Datenaufbereitung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-extrahieren\"></a>**1.1. Daten extrahieren**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datenaufbereitung stellt im Prozess des maschinellen Lernens oft einen entscheidenden, aber zugleich zeitaufwendigen Schritt dar. Sie umfasst diverse Techniken zur Säuberung, Transformation und Organisation der Rohdaten, um sie in ein für die Analyse passendes Format zu überführen. Diese Etappe legt das solide Fundament für die Erstellung eines Modells, da sie die Qualität und Relevanz der Daten gewährleistet. Dies trägt maßgeblich zur Präzision und Leistungsfähigkeit des endgültigen Modells bei [2].\n",
    "\n",
    "Im Kontext unseres Projektes verwenden wir folgende CSV-Dateien (CSV = Comma-Separated Values):\n",
    "\n",
    "- audi.csv\n",
    "- bmw.csv\n",
    "- ford.csv\n",
    "- hyundai.csv\n",
    "- mercedes.csv\n",
    "- skoda.csv\n",
    "- toyota.csv\n",
    "- vauxhall.csv\n",
    "- vw.csv\n",
    "\n",
    "Diese Dateien sind im Ordner **/data** gespeichert und werden nach dem Aufbereitungs- und Bereinigungsprozess im Ordner **/data (clean)** als einzige zusammengefasste CSV-Datei abgelegt.\n",
    "\n",
    "Für diesen Abschnitt wird ausschließlich auf die weit verbreitete **Pandas-Bibliothek** zurückgegriffen, welche sich als leistungsfähiges Werkzeug zur Datenmanipulation und -analyse etabliert hat. Hierbei lesen wir die Daten aus und stellen die Daten als sog. **DataFrames** dar, da sie eine standardisierte, zweidimensionale Struktur bieten, die das Speichern, Manipulieren und Analysieren von tabellarischen Daten vereinfacht, wodurch die Datenanalyse und -verarbeitung insgesamt effizienter und übersichtlicher wird [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir lesen nun die ersten CSV-Files aus, uns erst einmal einen Überblick zu verschaffen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audi =  pd.read_csv('../data/audi.csv')\n",
    "df_ford  =  pd.read_csv('../data/ford.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ford.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Befehl *df.shape* gibt uns Auskunft über die zugehörige Dimension unseres DataFrames. Die erste Zahl, gibt die Anzahl der Zeilen und die zweite Zahl, die Anzahl der Spalten (auch Variable oder Merkmale genannt) wieder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_audi.shape)\n",
    "print(df_ford.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um schließlich einen umfassenden Datensatz zu erhalten, fassen wir diesen in einem DataFrame zusammen, wobei wir eine zusätzliche Spalte hinzugefügt haben, die als brand bezeichnet wird und die Marke des Modells enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    '../data/audi.csv',\n",
    "    '../data/bmw.csv',\n",
    "    '../data/ford.csv',\n",
    "    '../data/hyundi.csv',\n",
    "    '../data/mercedes.csv',\n",
    "    '../data/skoda.csv',\n",
    "    '../data/toyota.csv',\n",
    "    '../data/vauxhall.csv',\n",
    "    '../data/vw.csv',\n",
    "]\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "# Durchlaufe alle Dateipfade und lade die CSV-Dateien\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    brand = file_path.split('/')[-1].split('.')[0]  # Extrahiere die Marke aus dem Dateinamen\n",
    "    df['brand'] = brand  # Füge eine Spalte mit der Marke hinzu\n",
    "    # Ändere die Reihenfolge der Spalten, um \"brand\" an den Anfang zu setzen\n",
    "    df = df[['brand'] + [col for col in df.columns if col != 'brand']]\n",
    "    all_dataframes.append(df)\n",
    "\n",
    "df = pd.concat(all_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-bereinigen\"></a>**1.2. Daten bereinigen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um redundate Daten vorzubeugen müssen wir vorab unsere Daten auf Duplikate prüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_count = df.duplicated().sum()\n",
    "print(duplicate_count)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insgesamt hat sich der Datensatz somit um 1457 Zeilen reduziert. \n",
    "\n",
    "Als nächsten Schritt prüfen wir den Datensatz anschließend auf fehlende Werte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt fehlende Werte in den Spalten tax, mpg, und tax(£). \n",
    "\n",
    "Gerade die Spalte tax(£) scheint in einem großen Teil des Datensatzes zu fehlen, weshalb wir die Spalte entfernen können, aufgrund fehlendem Informationsgehalt.\n",
    "\n",
    "\n",
    "Die anderen Spalten könnten wir die fehlenden Werte mit geeigneten Methoden behandeln, wie z.B. durch das Ausfüllen mit dem Durchschnittswert oder Median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['tax(£)'])\n",
    "df['tax'].fillna(df['tax'].median(), inplace=True)\n",
    "df['mpg'].fillna(df['mpg'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun nachdem wir geprüft haben, dass auch die Daten keine fehlenden Werte (**missing values**) mehr enthalten, müssen wir nun schauen das unsere Daten insgesamt plausibel sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['year'].min())\n",
    "print(df['year'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese problematischen Zeilen müssen wir nun einmal filtern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['year'] != 1970) & (df['year'] != 2060)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_counts = df['transmission'].value_counts()\n",
    "\n",
    "print(\"Einzelne eindeutige Werte und ihre Häufigkeit:\")\n",
    "print(unique_values_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_counts = df['fuelType'].value_counts()\n",
    "\n",
    "print(\"Einzelne eindeutige Werte und ihre Häufigkeit:\")\n",
    "print(unique_values_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"Daten-transformieren\"></a>**1.3. Daten transformieren**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es sich bei dem vorliegenden Datensatz um einen UK-Datensatz handelt, waren die Spalten und Zeilen ursprünglich für den englischsprachigen Raum konzipiert. Um jedoch eine bessere Interpretierbarkeit unserer Daten im deutschsprachigen Kontext zu gewährleisten, haben wir die Daten entsprechend transformiert. \n",
    "\n",
    "**Es ist wichtig zu betonen, dass die Konvertierung von Einheiten und die Abweichung von den Rohdaten problematisch sein können!**\n",
    "\n",
    "Hierbei wurde [4] hinzugezogen um noch einmal auf die Richtigkeit der Funktionen zu überprüfen und nachzujustieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion Umrechnung von (mpg) zu (l/100km)\n",
    "def mpg_to_l_per_100km(mpg):\n",
    "    return 235.215 / mpg\n",
    "\n",
    "# Funktion Umrechnung Meilen zu km\n",
    "def miles_to_km(miles):\n",
    "    return miles * 1.60934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    'Marke', 'Modell', 'Baujahr', 'Preis (£)', 'Getriebe', 'Kilometerstand', 'Kraftstoffart', 'Steuer (£)', 'Verbrauch (l/100km)', 'Motorgröße (l)']\n",
    "\n",
    "df['Getriebe'] = df['Getriebe'].map({'Manual': 'Manuell', \n",
    "                                     'Automatic': 'Automatik', \n",
    "                                     'Semi-Auto': 'Halbautomatisch'})\n",
    "\n",
    "df['Kraftstoffart'] = df['Kraftstoffart'].map({'Petrol': 'Benzin', \n",
    "                                               'Diesel': 'Diesel', \n",
    "                                               'Hybrid': 'Hybrid',\n",
    "                                               'Other': 'Andere',\n",
    "                                               'Electric': 'Elektrisch'})\n",
    "\n",
    "df['Kilometerstand'] = df['Kilometerstand'].apply(miles_to_km).astype(int)\n",
    "\n",
    "df['Verbrauch (l/100km)'] = df['Verbrauch (l/100km)'].apply(mpg_to_l_per_100km).round(2)\n",
    "\n",
    "df['Marke'] = df['Marke'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wechselkurs von Pfund zu Euro festlegen\n",
    "exchange_rate = 1.15\n",
    "\n",
    "# Umrechnung der Preise und Steuern von Pfund in Euro\n",
    "df['Preis (€)'] = df['Preis (£)'] * exchange_rate\n",
    "df['Steuer (€)'] = df['Steuer (£)'] * exchange_rate\n",
    "\n",
    "df['Preis (€)']\n",
    "\n",
    "\n",
    "# Entfernen der alten Spalten in Pfund\n",
    "df.drop(columns=['Preis (£)', 'Steuer (£)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = ['Marke', 'Modell', 'Getriebe', 'Kraftstoffart']\n",
    "\n",
    "# Leerzeichen in den ausgewählten Spalten entfernen\n",
    "df[string_columns] = df[string_columns].apply(lambda x: x.str.replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern unseres bereinigten Datensatzes in der Ordner **\\data (clean)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data (clean)/df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Explorative-Datenanalyse\"></a>**2. Explorative Datenanalyse**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Literaturverzeichnis**\n",
    "\n",
    "[1] https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes (01.08.2023)\n",
    "\n",
    "[2] Müller, A. C., & Guido, S. (2021). Introduction to Machine Learning with Python: A Guide for Data Scientists (2nd ed.). O'Reilly Media\n",
    "\n",
    "[3] McKinney, W. (2017). Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython (2nd ed.). O'Reilly Media.\n",
    "\n",
    "[4] OpenAI. (2023). Persönliche Kommunikation mit OpenAI's GPT-3.5 Modell. (01.08.2023)\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
